# Deep-Learning-
ржПржХржжржо ржХрж░рж┐ ржнрж╛ржЗ! ржирж┐ржЪрзЗ ржЖржорж┐ **Neural Network & RNN рж╕рж╣ рж╕ржорзНржкрзВрж░рзНржг Deep Learning Core Topics**тАУржПрж░ ржЙржкрж░ ржПржХржЭрж╛ржБржХ ржЧрзБржЫрж╛ржирзЛ, GitHub-ready Markdown style ржмрж╛ржВрж▓рж╛рзЯ ржирзЛржЯ ржмрж╛ржирж┐рзЯрзЗ ржжрж┐ржЪрзНржЫрж┐ тАФ ржпрзЗржоржиржЯрж╛ рждрзБржЗ GitHub-ржПрж░ `README.md` ржлрж╛ржЗрж▓рзЗ рж░рж╛ржЦрждрзЗ ржкрж╛рж░рж┐рж╕ ЁЯТб

---

# ЁЯза Neural Networks - ржмрж╛ржВрж▓рж╛рзЯ ржПржХржжржо ржкрж░рж┐рж╖рзНржХрж╛рж░ ржирзЛржЯ (Beginner тЖТ Intermediate)

## ЁЯУШ Table of Contents

1. [What is Neural Network?](#1)
2. [Neuron, Weight, Bias](#2)
3. [Activation Functions](#3)
4. [Forward & Backward Propagation](#4)
5. [Loss Function (with Examples)](#5)
6. [Optimizers](#6)
7. [Gradient Descent & Weight Update](#7)
8. [Epoch, Batch, Iteration](#8)
9. [ANN vs CNN vs RNN](#9)
10. [RNN - Core Concept](#10)
11. [Use Cases & Example Projects](#11)

---

<a name="1"></a>

## ЁЯза 1. What is Neural Network?

ржирж┐ржЙрж░рж╛рж▓ ржирзЗржЯржУрзЯрж╛рж░рзНржХ рж╣рж▓рзЛ ржорж╛ржирзБрж╖рзЗрж░ ржорж╕рзНрждрж┐рж╖рзНржХ ржЕржирзБржкрзНрж░рж╛ржгрж┐ржд ржПржХ ржзрж░ржирзЗрж░ **Machine Learning Algorithm**ред
ржПржЯрж╛ ржЗржиржкрзБржЯ ржбрзЗржЯрж╛ ржирж┐рзЯрзЗ, ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржлрж┐ржЪрж╛рж░ ржмрзЗрж░ ржХрж░рзЗ, ржПржХржЯрж╛ output ржжрзЗрзЯред

* ЁЯСБя╕ПтАНЁЯЧия╕П Input Layer тЖТ Hidden Layer(s) тЖТ Output Layer

---

<a name="2"></a>

## ЁЯФй 2. Neuron, Weight, Bias

### ЁЯОп Equation:

```
z = wтВБ┬╖xтВБ + wтВВ┬╖xтВВ + ... + b
a = activation(z)
```

| ржЙржкрж╛ржжрж╛ржи | ржХрж╛ржЬ                       |
| ------ | ------------------------- |
| `x`    | ржЗржиржкрзБржЯ                     |
| `w`    | ржУржЬржи: ржЗржиржкрзБржЯрзЗрж░ ржЧрзБрж░рзБрждрзНржм      |
| `b`    | Bias: ржЖржЙржЯржкрзБржЯржХрзЗ рж╢рж┐ржлржЯ ржХрж░рзЗ   |
| `a`    | Activation ржПрж░ ржкрж░рзЗрж░ Output |

---

<a name="3"></a>

## тЪЩя╕П 3. Activation Function

### ЁЯТб ржХрзЗржи ржжрж░ржХрж╛рж░?

Neural Network ржпрж╛рждрзЗ complex decision ржирж┐рждрзЗ ржкрж╛рж░рзЗ тАФ рждрж╛рж░ ржЬржирзНржп activation function ржжрж░ржХрж╛рж░ред

| ржирж╛ржо     | Range                        | ржмрзНржпржмрж╣рж╛рж░                   |
| ------- | ---------------------------- | ------------------------- |
| Sigmoid | 0 to 1                       | Binary classification     |
| Tanh    | -1 to 1                      | Centered data             |
| ReLU    | 0 to тИЮ                       | Most common, fast         |
| Softmax | 0 to 1 (probability sum = 1) | Multiclass classification |

---

<a name="4"></a>

## ЁЯФБ 4. Forward & Backward Propagation

### ЁЯЯй Forward:

Input тЖТ Weighted Sum тЖТ Activation тЖТ Output

### ЁЯЯе Backpropagation:

Loss тЖТ Gradient тЖТ Weight Update
ЁЯУМ Gradient ржмрзЗрж░ ржХрж░рзЗ optimizer ржХрзЗ ржжрзЗрзЯ

---

<a name="5"></a>

## ЁЯУЙ 5. Loss Function

**Loss Function** ржмрж▓рзЗ ржжрзЗрзЯ тАФ model ржХрждржЯрж╛ ржнрзБрж▓ ржХрж░ржЫрзЗред

| ржирж╛ржо                       | ржмрзНржпржмрж╣рж╛рж░                    | Example        |
| ------------------------- | -------------------------- | -------------- |
| MSE                       | Regression                 | Stock price    |
| MAE                       | Regression                 | House price    |
| Binary Cross-Entropy      | Binary classification      | Spam detection |
| Categorical Cross-Entropy | Multi-class classification | Cat/Dog/Horse  |

---

<a name="6"></a>

## тЪЩя╕П 6. Optimizers

Optimizer = **Weights ржХрж┐ржнрж╛ржмрзЗ ржЖржкржбрзЗржЯ рж╣ржмрзЗ** рж╕рзЗржЯрж╛ ржмрж▓рзЗ ржжрзЗрзЯред

| ржирж╛ржо     | ржмрзИрж╢рж┐рж╖рзНржЯрзНржп              |
| ------- | ---------------------- |
| SGD     | Basic version          |
| Adam    | рж╕ржмржЪрзЗржпрж╝рзЗ ржЬржиржкрзНрж░рж┐ржпрж╝, fast |
| RMSProp | ржнрж╛рж▓рзЛ RNN ржПрж░ ржЬржирзНржп       |
| Adagrad | Sparse data-friendly   |

---

<a name="7"></a>

## ЁЯзо 7. Gradient Descent & Weight Update

### ЁЯОп Update Formula:

```text
w = w - learning_rate ├Ч тИВL/тИВw
```

* тИВL/тИВw = gradient of loss wrt weight
* learning rate тЖТ ржХрждржЯрзБржХрзБ ржкрж░рж┐ржмрж░рзНрждржи рж╣ржмрзЗ

---

<a name="8"></a>

## ЁЯУж 8. Epoch, Batch, Iteration

| рж╢ржмрзНржж       | ржорж╛ржирзЗ                                             |
| ---------- | ------------------------------------------------ |
| Epoch      | ржкрзБрж░рзЛ ржбрзЗржЯрж╛рж╕рзЗржЯ рзз ржмрж╛рж░ train ржХрж░рж╛                     |
| Batch Size | ржХрждржЧрзБрж▓рзЛ sample ржПржХрж╕рж╛ржерзЗ train рж╣ржмрзЗ                   |
| Iteration  | ржПржХрзЗржХржЯрж╛ batch train рж╣ржУрзЯрж╛ (1 epoch = N iterations) |

ЁЯза Example:

* ржбрзЗржЯрж╛: 1000 image
* Batch size = 100
  тЖТ 1 Epoch = 10 Iteration

---

<a name="9"></a>

## ЁЯдЦ 9. ANN vs CNN vs RNN

| Network | ржмрзНржпржмрж╣рж╛рж░               | ржзрж░ржи             |
| ------- | --------------------- | --------------- |
| ANN     | Simple numeric data   | Static          |
| CNN     | Image, vision tasks   | Spatial pattern |
| RNN     | Language, time-series | Sequential      |

---

<a name="10"></a>

## ЁЯФБ 10. Recurrent Neural Network (RNN)

RNN ржЯрж╛ржЗржоржнрж┐рждрзНрждрж┐ржХ (sequential) ржбрзЗржЯрж╛ ржмрзЛржЭрзЗред ржЖржЧрзЗрж░ input ржоржирзЗ рж░рж╛ржЦрзЗред

### ЁЯза Equation:

```
hтВЬ = activation(Wx┬╖xтВЬ + Wh┬╖hтВЬтВЛтВБ + b)
```

### ЁЯФД ржмрзНржпржмрж╣рж╛рж░:

* ржнрж╛рж╖рж╛ (Text)
* рж╕рзНржкрж┐ржЪ
* ржЯрж╛ржЗржо рж╕рж┐рж░рж┐ржЬ (Weather, Stock)

### ЁЯзи рж╕ржорж╕рзНржпрж╛:

* Long-Term dependency ржнрзБрж▓рзЗ ржпрж╛рзЯ
* Gradient vanish рж╣рзЯ

ЁЯУМ рж╕ржорж╛ржзрж╛ржи тЖТ LSTM, GRU

---

<a name="11"></a>

## ЁЯзк 11. Example Project Ideas (Practice-Ready)

| ржкрзНрж░ржЬрзЗржХрзНржЯ                | ржмрж░рзНржгржирж╛                      |
| ----------------------- | --------------------------- |
| Digit Recognizer (CNN)  | ржЫржмрж┐рж░ ржнрж┐рждрж░ рж╕ржВржЦрзНржпрж╛ ржЪрж┐ржирзЗ       |
| Text Generator (RNN)    | ржмрж╛ржВрж▓рж╛ ржХржмрж┐рждрж╛ ржЬрзЗржирж╛рж░рзЗрж╢ржи        |
| Stock Prediction (RNN)  | ржЯрж╛ржЗржо рж╕рж┐рж░рж┐ржЬ forecasting      |
| Movie Review Classifier | Positive/Negative sentiment |
| Next Word Prediction    | "ржЖржорж┐ ржврж╛ржХрж╛..." тЖТ ржЖрж╕ржЫрж┐/ржЧрзЗржЫрж┐   |

---

## ЁЯОБ Bonus Tips

* тЬЕ Always normalize input
* тЬЕ Use ReLU in hidden, Softmax in output
* тЬЕ Try Adam optimizer first
* тЬЕ Track training vs validation loss


